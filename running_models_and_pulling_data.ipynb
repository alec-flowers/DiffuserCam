{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from diffcam.util import LOGPATH, load_pickle, RECONSTRUCTIONPATH, DATAPATH\n",
    "from scripts.evaluation import evaluate\n",
    "from diffcam.util import DATAPATH, RECONSTRUCTIONPATH, print_image_info, resize, rgb2gray\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff451ed7",
   "metadata": {},
   "source": [
    "# Running One Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849a7fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameters to set\n",
    "\n",
    "data = 'our_images'  # Uses our image data\n",
    "n_files = 1          # None yields all of our files\n",
    "algo = 'glasso'      # which algorithm to run, can check the optimization file for options\n",
    "n_iter = 10          # This can either be an int or a list. A list will run the cumulative sum in iterations while outputing imgages and save logs at each int value. \n",
    "gray = False         # RGB or grayscale reconstruction\n",
    "lambda_ = 1e-6       # hyperparameter lambda\n",
    "delta = 5            # hyperparameter delta\n",
    "downsample = 4\n",
    "disp = 50\n",
    "flip = False\n",
    "bayer = False\n",
    "bg = None\n",
    "rg = None\n",
    "gamma = None\n",
    "save = True         # Save logs and reconstructed images to folders logs and reconstruction under data folder.\n",
    "plot = True         # Display images as reconstructions occur\n",
    "single_psf = False\n",
    "psf_fp = rf'{str(DATAPATH)}{os.sep}psf{os.sep}psf_rgb_ours.png'  #which psf to use\n",
    "\n",
    "\n",
    "evaluate(data, n_files, psf_fp, algo, lambda_, delta, n_iter, downsample, disp, flip, gray, bayer, bg, rg, gamma, save, plot, single_psf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9948b1",
   "metadata": {},
   "source": [
    "Note: If you want to set up multiple tests you can use the run.py file which allows you to set up the running of many tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab106ccc",
   "metadata": {},
   "source": [
    "# Pulling Data from Logs after runs\n",
    "After we have done our run, we want to look at the data that comes from it. This can be done useing the following code. Note: Make sure to set the save flag as True in order to save the logs and all the photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name, and_contain = ['p'], or_contain = ['p'],  not_contains = ['zzzz']):\n",
    "    \"\"\"\n",
    "    Use this file to load all the pickles that you want. \n",
    "    \n",
    "    ex: pickle = load_data(\"ridge*.pkl\",['.01', '1000'],['.02','.03'],[10_])\n",
    "    This will match all names that start with ridge, that contain '0.1' AND '1000', that contain '.02' OR '.03' and don't contain '10_'\n",
    "    \n",
    "    \"\"\"\n",
    "    files = []\n",
    "    files.extend(glob.glob(os.path.join(LOGPATH,name),recursive=True))\n",
    "\n",
    "    pickles = []\n",
    "    for f in files:\n",
    "        if all(x in f for x in and_contain):\n",
    "            if any(x in f for x in or_contain):\n",
    "                if not any(x in f for x in not_contains):\n",
    "                    pickles.append(load_pickle(f))\n",
    "        \n",
    "    return pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649017f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_dict(pickle,\n",
    "                       iters,\n",
    "                       images = ['img1_rgb', 'img3_rgb', 'img4_rgb', 'img5_rgb', 'img6_rgb', 'img7_rgb', 'img8_rgb']):\n",
    "    \n",
    "    \"\"\"\n",
    "    This will pull data out of the dictionaries and put them into lists that can be manipulated.\n",
    "    \n",
    "    pickle: list of pickles from load_data\n",
    "    iters: which iteration to pull data from\n",
    "    \"\"\"\n",
    "    \n",
    "    lambda_ = []\n",
    "    algo = []\n",
    "    delta = []\n",
    "    \n",
    "    mse = []\n",
    "    psnr = []\n",
    "    ssim = []\n",
    "    lpips = []\n",
    "    n_iter = []\n",
    "    lenseless = []\n",
    "    process_time = []\n",
    "\n",
    "    for save in pickle:\n",
    "        algo.append(save['algo'])\n",
    "        lambda_.append(save['lambda'])\n",
    "        delta.append(save['delta'])\n",
    "\n",
    "        fp = []\n",
    "        m = []\n",
    "        p = []\n",
    "        s = []\n",
    "        l = []\n",
    "        time = []\n",
    "        for im in images:\n",
    "            pic = save[im]\n",
    "            for i in iters:\n",
    "                fp.append(pic[str(i)]['recon_fp'])\n",
    "                m.append(pic[str(i)]['mse'])\n",
    "                p.append(pic[str(i)]['psnr'])\n",
    "                s.append(pic[str(i)]['ssim'])\n",
    "                l.append(pic[str(i)]['lpips'])\n",
    "                time.append(pic[str(i)]['process_time'])\n",
    "        lenseless.append(fp)\n",
    "        mse.append(m)\n",
    "        psnr.append(p)\n",
    "        ssim.append(s)\n",
    "        lpips.append(l)\n",
    "        process_time.append(time)\n",
    "    return lambda_, algo, delta, mse, psnr, ssim, lpips, n_iter, images, lenseless, process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc05cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo(path, color = False):\n",
    "    \"\"\"\n",
    "    Grabs the photo from the RECONSTRUCTION folder and turns it into data.\n",
    "    path: path to data\n",
    "    color: if data needs a color correction from cv2\n",
    "    \"\"\"\n",
    "    \n",
    "    end = os.path.split(path)[-1]\n",
    "    path = os.path.join(RECONSTRUCTIONPATH, end)\n",
    "    data = mpimg.imread(path)\n",
    "    if color:\n",
    "        data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887ef28d",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle = load_data(\"ridge*.pkl\",['.01', '1000'],['.02','.03'],[10_])\n",
    "\n",
    "lambda_, algo, delta, mse, psnr, ssim, lpips, n_iter, images, lenseless, process_time = get_data_from_dict(pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910edf9",
   "metadata": {},
   "source": [
    "Then you can manipulate your data and we used this to plot everything in our report. The old code is in plots_old. However because of how the logging changed over time it is outdated and a bit messy. You can look at it as a reference but the code will not compile and it will not run. We also do not provide all our data in the repo since it is very heavy but you can do your own runs and use the above to pull the information from it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffcam_env",
   "language": "python",
   "name": "diffcam_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
